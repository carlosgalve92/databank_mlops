{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effe5706",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c6170",
   "metadata": {},
   "source": [
    "Scikit-learn es una biblioteca esencial para el aprendizaje automático en Python construida sobre numpy. Ofrece una interfaz simple y eficiente para realizar tareas como preprocesamiento de datos, clasificación, regresión, agrupamiento, y evaluación de modelos. Es ampliamente utilizada tanto en investigación como en producción, y se integra bien con otras herramientas de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ba50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pathlib\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341fe15",
   "metadata": {},
   "source": [
    "## Transformación personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mb_woe_encoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Clase creada como encoder de woe sobre variables\n",
    "    categoricas. Esta transformacion podría utilizarse\n",
    "    en un pipeline de sklearn\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pc_min_other=0.05, keep_na=True):\n",
    "        \"\"\" \"\"\"\n",
    "        self.pc_min_other = pc_min_other\n",
    "        self.keep_na = keep_na\n",
    "        self.dict_woe = {}\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y = y.values.squeeze()\n",
    "\n",
    "        for c in self.feature_names_in_:\n",
    "            self.dict_woe[c] = {\"WOES\": {}, \"OTHERS\": None}\n",
    "            # Se eliminan registros con NAs\n",
    "            target_sm = y[np.where(X[c].notna())]\n",
    "            feature_sm = X.loc[(X[c].notna().values), [c]]\n",
    "\n",
    "            df_aux = pd.concat(\n",
    "                [\n",
    "                    feature_sm.reset_index(drop=True),\n",
    "                    pd.DataFrame(target_sm.reshape(-1, 1)),\n",
    "                ],\n",
    "                axis=1,\n",
    "                ignore_index=False,\n",
    "            )\n",
    "            # Se calcula el numero de eventos por categoria\n",
    "            event_x_cat = df_aux.groupby(c).sum()\n",
    "            # Se calcula el numero de registros de cada categoria\n",
    "            reg_x_cat = df_aux.groupby(c).count()\n",
    "            # Se calcula el numero de no eventos por categoria\n",
    "            non_event_x_cat = reg_x_cat - event_x_cat\n",
    "\n",
    "            # Se calcula woe (Esta al reves de la teorica)\n",
    "            woe = np.log((event_x_cat + 1) / (non_event_x_cat + 1))\n",
    "\n",
    "            # Se resetean indices para tener columna con categorias\n",
    "            woe = woe.reset_index()\n",
    "            # Se renombran columnas\n",
    "            woe.columns = [\"CATEGORIA\", \"VALOR_WOE\"]\n",
    "\n",
    "            # Se calcula el numero de registros minimos que debe tener\n",
    "            # una categoria para no ser considerada minoritaria\n",
    "            lim_value_other = self.pc_min_other * len(y)\n",
    "\n",
    "            # Se obtienen las categorias minoritarias\n",
    "            ls_cat_excl = (\n",
    "                reg_x_cat[(reg_x_cat < lim_value_other).values]\n",
    "                .reset_index()\n",
    "                .iloc[:, 0]\n",
    "                .tolist()\n",
    "            )\n",
    "\n",
    "            # Se filtran WoE para quedarse solo con las categorias\n",
    "            # mayoritarias\n",
    "            woe_filtrado = woe[~(woe[\"CATEGORIA\"].isin(ls_cat_excl))]\n",
    "            # Se almacenan los woe en formato pares clave-valor de\n",
    "            # categoria-valor\n",
    "            self.dict_woe[c][\"WOES\"] = dict(\n",
    "                zip(woe_filtrado[\"CATEGORIA\"], woe_filtrado[\"VALOR_WOE\"])\n",
    "            )\n",
    "\n",
    "            # Se calcula el woe comun para las clases minoritarias\n",
    "            event_total_other = target_sm[\n",
    "                np.where(~(feature_sm.isin(ls_cat_excl).values.squeeze()))\n",
    "            ].sum()\n",
    "            non_event_other = (\n",
    "                target_sm[\n",
    "                    np.where(~(feature_sm.isin(ls_cat_excl).values.squeeze()))\n",
    "                ].size\n",
    "                - event_total_other\n",
    "            )\n",
    "            self.dict_woe[c][\"OTHERS\"] = np.log(\n",
    "                (event_total_other + 1) / (non_event_other + 1)\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" \"\"\"\n",
    "        for c in X.columns:\n",
    "            X[c] = (\n",
    "                X[c]\n",
    "                .map(\n",
    "                    lambda k: self._get_value_from_dict(\n",
    "                        k, self.dict_woe[c][\"WOES\"], self.dict_woe[c][\"OTHERS\"]\n",
    "                    )\n",
    "                )\n",
    "                .astype(np.float64)\n",
    "            )\n",
    "\n",
    "        return X\n",
    "\n",
    "    # def fit_transform(self, X, y=None):\n",
    "    #     \"\"\"\n",
    "    #     \"\"\"\n",
    "    #     return self.fit(X, y).transform(X)\n",
    "\n",
    "    def _get_value_from_dict(self, key_dict, dict_values, value_other):\n",
    "        \"\"\"\n",
    "        Función utilizada para que sustituye clave de un diccionario\n",
    "        por su valor. En caso de que la clave sea None, np.nan,\n",
    "        esta se sustituye por np.nan. Y para cuando no es\n",
    "        desconocido el valor pero tampoco aparece en el diccionario\n",
    "        se sustituye por value_other\n",
    "\n",
    "        Keyword arguments:\n",
    "        :key_dict: clave a sustituir por su valor\n",
    "        :dict_values: diccionario con las tuplas clave-valor\n",
    "        \"\"\"\n",
    "        if (pd.isna(key_dict)) and (self.keep_na):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return dict_values.get(key_dict, value_other)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)\n",
    "\n",
    "\n",
    "class mb_clean_text(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, replace_value=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.replace_value = replace_value\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" \"\"\"\n",
    "        for c in X.columns:\n",
    "            X[c] = X[c].str.replace(r\"_\", \"\").str.strip()\n",
    "            X.loc[(X[c] == \"\"), c] = self.replace_value\n",
    "\n",
    "            if self.replace_value is not None:\n",
    "                X.loc[(X[c].isna()), c] = self.replace_value\n",
    "\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mb_clean_text_number(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" \"\"\"\n",
    "        for c in X.columns:\n",
    "            X[c] = X[c].astype(str).str.strip('_ ,\"')\n",
    "            X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a457c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mb_standard_scaler(StandardScaler):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Guardamos los nombres de columnas si es DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_in_ = X.columns.to_numpy()\n",
    "        else:\n",
    "            self.feature_names_in_ = None\n",
    "        return super().fit(X, y)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)\n",
    "\n",
    "\n",
    "class mb_simple_imputer(SimpleImputer):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Guardamos los nombres de columnas si es DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_in_ = X.columns.to_numpy()\n",
    "        else:\n",
    "            self.feature_names_in_ = None\n",
    "        return super().fit(X, y)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc58a81",
   "metadata": {},
   "source": [
    "## Descarga del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c12300",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_DATASET = r\"parisrohan/credit-score-classification\"\n",
    "PATH_DATA = pathlib.Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files(URL_DATASET, path=PATH_DATA, unzip=True)\n",
    "filenames = [f.name for f in kaggle.api.dataset_list_files(URL_DATASET).files]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0011d15",
   "metadata": {},
   "source": [
    "## Carga data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH_DATA.joinpath(filenames[1]))\n",
    "data.columns = data.columns.str.strip().str.upper()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\n",
    "    \"OCCUPATION\",\n",
    "    \"AGE\",\n",
    "    \"ANNUAL_INCOME\",\n",
    "    \"NUM_OF_LOAN\",\n",
    "    \"NUM_OF_DELAYED_PAYMENT\",\n",
    "    \"CHANGED_CREDIT_LIMIT\",\n",
    "    \"OUTSTANDING_DEBT\",\n",
    "    \"AMOUNT_INVESTED_MONTHLY\",\n",
    "    \"MONTHLY_BALANCE\",\n",
    "]:\n",
    "    print(data.loc[:, c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e09454",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"MONTHLY_INHAND_SALARY\",\n",
    "        \"NUM_BANK_ACCOUNTS\",\n",
    "        \"NUM_CREDIT_CARD\",\n",
    "        \"INTEREST_RATE\",\n",
    "        \"DELAY_FROM_DUE_DATE\",\n",
    "        \"NUM_CREDIT_INQUIRIES\",\n",
    "        \"CREDIT_UTILIZATION_RATIO\",\n",
    "        \"TOTAL_EMI_PER_MONTH\",\n",
    "    ],\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, [\"CREDIT_SCORE\"]].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f14b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"OCCUPATION\",\n",
    "        \"AGE\",\n",
    "        \"ANNUAL_INCOME\",\n",
    "        \"NUM_OF_LOAN\",\n",
    "        \"NUM_OF_DELAYED_PAYMENT\",\n",
    "        \"CHANGED_CREDIT_LIMIT\",\n",
    "        \"OUTSTANDING_DEBT\",\n",
    "        \"AMOUNT_INVESTED_MONTHLY\",\n",
    "        \"MONTHLY_BALANCE\",\n",
    "        \"MONTHLY_INHAND_SALARY\",\n",
    "        \"NUM_BANK_ACCOUNTS\",\n",
    "        \"NUM_CREDIT_CARD\",\n",
    "        \"INTEREST_RATE\",\n",
    "        \"DELAY_FROM_DUE_DATE\",\n",
    "        \"NUM_CREDIT_INQUIRIES\",\n",
    "        \"CREDIT_UTILIZATION_RATIO\",\n",
    "        \"TOTAL_EMI_PER_MONTH\",\n",
    "        \"CREDIT_SCORE\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e9ded",
   "metadata": {},
   "source": [
    "## Preparación train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2025\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_target = LabelEncoder()\n",
    "y = encoder_target.fit_transform(data[\"CREDIT_SCORE\"])\n",
    "print(encoder_target.inverse_transform(y))\n",
    "print(encoder_target.classes_)\n",
    "y = pd.DataFrame(np.where((y == 1), 1, 0), columns=[\"CREDIT_SCORE\"])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns=[\"CREDIT_SCORE\"]),\n",
    "    y.values.ravel(),\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y.values.ravel(),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dfa61",
   "metadata": {},
   "source": [
    "## Generación del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_cat = Pipeline(\n",
    "    [\n",
    "        (\"clean\", mb_clean_text(\"MISSING\")),\n",
    "        (\"woe\", mb_woe_encoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl_cat_num = Pipeline(\n",
    "    [\n",
    "        (\"clean\", mb_clean_text_number()),\n",
    "        (\"mb_simple_imputer\", mb_simple_imputer(strategy=\"median\")),\n",
    "        (\"scaler\", mb_standard_scaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl_num = Pipeline(\n",
    "    [\n",
    "        (\"mb_simple_imputer\", mb_simple_imputer(strategy=\"median\")),\n",
    "        (\"scaler\", mb_standard_scaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl_preprocess = ColumnTransformer(\n",
    "    [\n",
    "        (\"prep_cat\", pl_cat, [\"OCCUPATION\"]),\n",
    "        (\n",
    "            \"prep_cat_num\",\n",
    "            pl_cat_num,\n",
    "            [\n",
    "                \"AGE\",\n",
    "                \"ANNUAL_INCOME\",\n",
    "                \"NUM_OF_LOAN\",\n",
    "                \"NUM_OF_DELAYED_PAYMENT\",\n",
    "                \"CHANGED_CREDIT_LIMIT\",\n",
    "                \"OUTSTANDING_DEBT\",\n",
    "                \"AMOUNT_INVESTED_MONTHLY\",\n",
    "                \"MONTHLY_BALANCE\",\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            \"prep_num\",\n",
    "            pl_num,\n",
    "            [\n",
    "                \"MONTHLY_INHAND_SALARY\",\n",
    "                \"NUM_BANK_ACCOUNTS\",\n",
    "                \"NUM_CREDIT_CARD\",\n",
    "                \"INTEREST_RATE\",\n",
    "                \"DELAY_FROM_DUE_DATE\",\n",
    "                \"NUM_CREDIT_INQUIRIES\",\n",
    "                \"CREDIT_UTILIZATION_RATIO\",\n",
    "                \"TOTAL_EMI_PER_MONTH\",\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    force_int_remainder_cols=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baadada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90cfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pl_preprocess.fit_transform(x_train, y_train)\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70bbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_preprocess.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c978bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_preprocess.transformers_[0][1].named_steps[\"woe\"].dict_woe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc95c2",
   "metadata": {},
   "source": [
    "## Pipeline con preprocesamiento y modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361aa76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = Pipeline(\n",
    "    [(\"pl_prep\", pl_preprocess), (\"lineal_model\", LogisticRegression())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c59e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695feb1",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Gini con Regresion Lineal en Train: {2 * roc_auc_score(y_train, pipeline_model.predict_proba(x_train)[:, 1]) - 1: .2%}\"\n",
    ")\n",
    "print(\n",
    "    f\"Gini con Regresion Lineal en Test: {2 * roc_auc_score(y_test, pipeline_model.predict_proba(x_test)[:, 1]) - 1: .2%}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
