{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5f151d",
   "metadata": {},
   "source": [
    "# Pytorch & Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdc074",
   "metadata": {},
   "source": [
    "**Tensorflow** TensorFlow es una biblioteca de código abierto para aprendizaje automático a través de un rango de tareas, y desarrollado por Google para satisfacer sus necesidades de sistemas capaces de construir y entrenar redes neuronales para detectar y descifrar patrones y correlaciones, análogos al aprendizaje y razonamiento usados por los humanos. \n",
    "\n",
    "**PyTorch** es un marco de deep learning de código abierto basado en software que se utiliza para crear redes neuronales, combinando la biblioteca de machine learning (ML) de Torch con una API de alto nivel basada en Python. Su flexibilidad y facilidad de uso, entre otros beneficios, lo han convertido en el marco de ML líder para las comunidades académicas y de investigación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47670701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pathlib\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f6860",
   "metadata": {},
   "source": [
    "## Transformación personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mb_woe_encoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Clase creada como encoder de woe sobre variables\n",
    "    categoricas. Esta transformacion podría utilizarse\n",
    "    en un pipeline de sklearn\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pc_min_other=0.05, keep_na=True):\n",
    "        \"\"\" \"\"\"\n",
    "        self.pc_min_other = pc_min_other\n",
    "        self.keep_na = keep_na\n",
    "        self.dict_woe = {}\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y = y.values.squeeze()\n",
    "\n",
    "        for c in self.feature_names_in_:\n",
    "            self.dict_woe[c] = {\"WOES\": {}, \"OTHERS\": None}\n",
    "            # Se eliminan registros con NAs\n",
    "            target_sm = y[np.where(X[c].notna())]\n",
    "            feature_sm = X.loc[(X[c].notna().values), [c]]\n",
    "\n",
    "            df_aux = pd.concat(\n",
    "                [\n",
    "                    feature_sm.reset_index(drop=True),\n",
    "                    pd.DataFrame(target_sm.reshape(-1, 1)),\n",
    "                ],\n",
    "                axis=1,\n",
    "                ignore_index=False,\n",
    "            )\n",
    "            # Se calcula el numero de eventos por categoria\n",
    "            event_x_cat = df_aux.groupby(c).sum()\n",
    "            # Se calcula el numero de registros de cada categoria\n",
    "            reg_x_cat = df_aux.groupby(c).count()\n",
    "            # Se calcula el numero de no eventos por categoria\n",
    "            non_event_x_cat = reg_x_cat - event_x_cat\n",
    "\n",
    "            # Se calcula woe (Esta al reves de la teorica)\n",
    "            woe = np.log((event_x_cat + 1) / (non_event_x_cat + 1))\n",
    "\n",
    "            # Se resetean indices para tener columna con categorias\n",
    "            woe = woe.reset_index()\n",
    "            # Se renombran columnas\n",
    "            woe.columns = [\"CATEGORIA\", \"VALOR_WOE\"]\n",
    "\n",
    "            # Se calcula el numero de registros minimos que debe tener\n",
    "            # una categoria para no ser considerada minoritaria\n",
    "            lim_value_other = self.pc_min_other * len(y)\n",
    "\n",
    "            # Se obtienen las categorias minoritarias\n",
    "            ls_cat_excl = (\n",
    "                reg_x_cat[(reg_x_cat < lim_value_other).values]\n",
    "                .reset_index()\n",
    "                .iloc[:, 0]\n",
    "                .tolist()\n",
    "            )\n",
    "\n",
    "            # Se filtran WoE para quedarse solo con las categorias\n",
    "            # mayoritarias\n",
    "            woe_filtrado = woe[~(woe[\"CATEGORIA\"].isin(ls_cat_excl))]\n",
    "            # Se almacenan los woe en formato pares clave-valor de\n",
    "            # categoria-valor\n",
    "            self.dict_woe[c][\"WOES\"] = dict(\n",
    "                zip(woe_filtrado[\"CATEGORIA\"], woe_filtrado[\"VALOR_WOE\"])\n",
    "            )\n",
    "\n",
    "            # Se calcula el woe comun para las clases minoritarias\n",
    "            event_total_other = target_sm[\n",
    "                np.where(~(feature_sm.isin(ls_cat_excl).values.squeeze()))\n",
    "            ].sum()\n",
    "            non_event_other = (\n",
    "                target_sm[\n",
    "                    np.where(~(feature_sm.isin(ls_cat_excl).values.squeeze()))\n",
    "                ].size\n",
    "                - event_total_other\n",
    "            )\n",
    "            self.dict_woe[c][\"OTHERS\"] = np.log(\n",
    "                (event_total_other + 1) / (non_event_other + 1)\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" \"\"\"\n",
    "        for c in X.columns:\n",
    "            X[c] = (\n",
    "                X[c]\n",
    "                .map(\n",
    "                    lambda k: self._get_value_from_dict(\n",
    "                        k, self.dict_woe[c][\"WOES\"], self.dict_woe[c][\"OTHERS\"]\n",
    "                    )\n",
    "                )\n",
    "                .astype(np.float64)\n",
    "            )\n",
    "\n",
    "        return X\n",
    "\n",
    "    # def fit_transform(self, X, y=None):\n",
    "    #     \"\"\"\n",
    "    #     \"\"\"\n",
    "    #     return self.fit(X, y).transform(X)\n",
    "\n",
    "    def _get_value_from_dict(self, key_dict, dict_values, value_other):\n",
    "        \"\"\"\n",
    "        Función utilizada para que sustituye clave de un diccionario\n",
    "        por su valor. En caso de que la clave sea None, np.nan,\n",
    "        esta se sustituye por np.nan. Y para cuando no es\n",
    "        desconocido el valor pero tampoco aparece en el diccionario\n",
    "        se sustituye por value_other\n",
    "\n",
    "        Keyword arguments:\n",
    "        :key_dict: clave a sustituir por su valor\n",
    "        :dict_values: diccionario con las tuplas clave-valor\n",
    "        \"\"\"\n",
    "        if (pd.isna(key_dict)) and (self.keep_na):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return dict_values.get(key_dict, value_other)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)\n",
    "\n",
    "\n",
    "class mb_clean_text(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, replace_value=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.replace_value = replace_value\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" \"\"\"\n",
    "        for c in X.columns:\n",
    "            X[c] = X[c].str.replace(r\"_\", \"\").str.strip()\n",
    "            X.loc[(X[c] == \"\"), c] = self.replace_value\n",
    "\n",
    "            if self.replace_value is not None:\n",
    "                X.loc[(X[c].isna()), c] = self.replace_value\n",
    "\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a21f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mb_clean_text_number(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" \"\"\"\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" \"\"\"\n",
    "        for c in X.columns:\n",
    "            X[c] = X[c].astype(str).str.strip('_ ,\"')\n",
    "            X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae91a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mb_standard_scaler(StandardScaler):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Guardamos los nombres de columnas si es DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_in_ = X.columns.to_numpy()\n",
    "        else:\n",
    "            self.feature_names_in_ = None\n",
    "        return super().fit(X, y)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)\n",
    "\n",
    "\n",
    "class mb_simple_imputer(SimpleImputer):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_names_in_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Guardamos los nombres de columnas si es DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_in_ = X.columns.to_numpy()\n",
    "        else:\n",
    "            self.feature_names_in_ = None\n",
    "        return super().fit(X, y)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        check_is_fitted(self)\n",
    "        if input_features is None:\n",
    "            input_features = self.feature_names_in_\n",
    "        return np.array(input_features, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97125f93",
   "metadata": {},
   "source": [
    "## Descarga del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_DATASET = r\"parisrohan/credit-score-classification\"\n",
    "PATH_DATA = pathlib.Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files(URL_DATASET, path=PATH_DATA, unzip=True)\n",
    "filenames = [f.name for f in kaggle.api.dataset_list_files(URL_DATASET).files]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6db116",
   "metadata": {},
   "source": [
    "## Carga data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH_DATA.joinpath(filenames[1]), low_memory=False)\n",
    "data.columns = data.columns.str.strip().str.upper()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc874d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\n",
    "    \"OCCUPATION\",\n",
    "    \"AGE\",\n",
    "    \"ANNUAL_INCOME\",\n",
    "    \"NUM_OF_LOAN\",\n",
    "    \"NUM_OF_DELAYED_PAYMENT\",\n",
    "    \"CHANGED_CREDIT_LIMIT\",\n",
    "    \"OUTSTANDING_DEBT\",\n",
    "    \"AMOUNT_INVESTED_MONTHLY\",\n",
    "    \"MONTHLY_BALANCE\",\n",
    "]:\n",
    "    print(data.loc[:, c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d881e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"MONTHLY_INHAND_SALARY\",\n",
    "        \"NUM_BANK_ACCOUNTS\",\n",
    "        \"NUM_CREDIT_CARD\",\n",
    "        \"INTEREST_RATE\",\n",
    "        \"DELAY_FROM_DUE_DATE\",\n",
    "        \"NUM_CREDIT_INQUIRIES\",\n",
    "        \"CREDIT_UTILIZATION_RATIO\",\n",
    "        \"TOTAL_EMI_PER_MONTH\",\n",
    "    ],\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, [\"CREDIT_SCORE\"]].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ef62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"OCCUPATION\",\n",
    "        \"AGE\",\n",
    "        \"ANNUAL_INCOME\",\n",
    "        \"NUM_OF_LOAN\",\n",
    "        \"NUM_OF_DELAYED_PAYMENT\",\n",
    "        \"CHANGED_CREDIT_LIMIT\",\n",
    "        \"OUTSTANDING_DEBT\",\n",
    "        \"AMOUNT_INVESTED_MONTHLY\",\n",
    "        \"MONTHLY_BALANCE\",\n",
    "        \"MONTHLY_INHAND_SALARY\",\n",
    "        \"NUM_BANK_ACCOUNTS\",\n",
    "        \"NUM_CREDIT_CARD\",\n",
    "        \"INTEREST_RATE\",\n",
    "        \"DELAY_FROM_DUE_DATE\",\n",
    "        \"NUM_CREDIT_INQUIRIES\",\n",
    "        \"CREDIT_UTILIZATION_RATIO\",\n",
    "        \"TOTAL_EMI_PER_MONTH\",\n",
    "        \"CREDIT_SCORE\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f442110",
   "metadata": {},
   "source": [
    "## Preparación train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2025\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_target = LabelEncoder()\n",
    "y = encoder_target.fit_transform(data[\"CREDIT_SCORE\"])\n",
    "print(y)\n",
    "print(encoder_target.inverse_transform(y))\n",
    "print(encoder_target.classes_)\n",
    "y = pd.DataFrame(np.where((y == 1), 1, 0), columns=[\"CREDIT_SCORE\"])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns=[\"CREDIT_SCORE\"]),\n",
    "    y.values.ravel(),\n",
    "    test_size=0.2,\n",
    "    random_state=2025,\n",
    "    stratify=y.values.ravel(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0ca4a2",
   "metadata": {},
   "source": [
    "## Generación del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_cat = Pipeline(\n",
    "    [\n",
    "        (\"clean\", mb_clean_text(\"MISSING\")),\n",
    "        (\"woe\", mb_woe_encoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl_cat_num = Pipeline(\n",
    "    [\n",
    "        (\"clean\", mb_clean_text_number()),\n",
    "        (\"mb_simple_imputer\", mb_simple_imputer(strategy=\"median\")),\n",
    "        (\"scaler\", mb_standard_scaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl_num = Pipeline(\n",
    "    [\n",
    "        (\"mb_simple_imputer\", mb_simple_imputer(strategy=\"median\")),\n",
    "        (\"scaler\", mb_standard_scaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl_preprocess = ColumnTransformer(\n",
    "    [\n",
    "        (\"prep_cat\", pl_cat, [\"OCCUPATION\"]),\n",
    "        (\n",
    "            \"prep_cat_num\",\n",
    "            pl_cat_num,\n",
    "            [\n",
    "                \"AGE\",\n",
    "                \"ANNUAL_INCOME\",\n",
    "                \"NUM_OF_LOAN\",\n",
    "                \"NUM_OF_DELAYED_PAYMENT\",\n",
    "                \"CHANGED_CREDIT_LIMIT\",\n",
    "                \"OUTSTANDING_DEBT\",\n",
    "                \"AMOUNT_INVESTED_MONTHLY\",\n",
    "                \"MONTHLY_BALANCE\",\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            \"prep_num\",\n",
    "            pl_num,\n",
    "            [\n",
    "                \"MONTHLY_INHAND_SALARY\",\n",
    "                \"NUM_BANK_ACCOUNTS\",\n",
    "                \"NUM_CREDIT_CARD\",\n",
    "                \"INTEREST_RATE\",\n",
    "                \"DELAY_FROM_DUE_DATE\",\n",
    "                \"NUM_CREDIT_INQUIRIES\",\n",
    "                \"CREDIT_UTILIZATION_RATIO\",\n",
    "                \"TOTAL_EMI_PER_MONTH\",\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    force_int_remainder_cols=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723be490",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c382d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_clean = pl_preprocess.fit_transform(x_train, y_train)\n",
    "x_train_clean = pd.DataFrame(\n",
    "    x_train_clean, columns=pl_preprocess.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fff632",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_clean = pl_preprocess.transform(x_test)\n",
    "x_test_clean = pd.DataFrame(x_test_clean, columns=pl_preprocess.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd87a8",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e37d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se establece semilla\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d848edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo secuencial en Keras (TensorFlow)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(shape=(x_train_clean.shape[1],)),  # Capa de entrada\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),  # Primera capa oculta\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),  # Segunda capa oculta\n",
    "        tf.keras.layers.Dense(\n",
    "            1, activation=\"sigmoid\"\n",
    "        ),  # Capa de salida (sigmoide para clasificación binaria)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"auc\"])\n",
    "\n",
    "# Crear el callback EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Monitorea la pérdida en el conjunto de validación\n",
    "    patience=3,  # Espera 3 épocas sin mejora\n",
    "    restore_best_weights=True,\n",
    ")  # Restaura los mejores pesos\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(\n",
    "    x_train_clean.values,\n",
    "    y_train[:, np.newaxis],\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test_clean, y_test),\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, auc = model.evaluate(x_train_clean.values, y_train)\n",
    "print(f\"Train Gini: {2 * auc - 1}\")\n",
    "loss, auc = model.evaluate(x_test_clean.values, y_test)\n",
    "print(f\"Test Gini: {2 * auc - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafa755",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3848da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se establece semilla\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82daa291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los datos a tensores de PyTorch\n",
    "x_train_tensor = torch.tensor(x_train_clean.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Convertir los datos a tensores de PyTorch\n",
    "x_test_tensor = torch.tensor(x_test_clean.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d199668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataLoader para el entrenamiento\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(SEED)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la red neuronal en PyTorch\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(\n",
    "            x_train_tensor.shape[1], 64\n",
    "        )  # Capa de entrada (3 características)\n",
    "        self.layer2 = nn.Linear(64, 32)  # Primera capa oculta\n",
    "        self.layer3 = nn.Linear(32, 1)  # Capa de salida\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))  # ReLU en la primera capa oculta\n",
    "        x = torch.relu(self.layer2(x))  # ReLU en la segunda capa oculta\n",
    "        x = self.sigmoid(self.layer3(x))  # Sigmoide en la capa de salida\n",
    "        return x\n",
    "\n",
    "\n",
    "# Crear el modelo\n",
    "model = MLP()\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # Calcular la pérdida\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualizar los pesos\n",
    "        optimizer.step()\n",
    "\n",
    "    # Imprimir el progreso cada 10 épocas\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluación del modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        rf\"Gini Train: {2 * roc_auc_score(y_train_tensor, model(x_train_tensor)) - 1: .2%}\"\n",
    "    )\n",
    "    print(\n",
    "        rf\"Gini Test: {2 * roc_auc_score(y_test_tensor, model(x_test_tensor)) - 1: .2%}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
